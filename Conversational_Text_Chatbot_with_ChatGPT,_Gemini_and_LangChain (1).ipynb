{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTzBUFWQ-OWj"
      },
      "source": [
        "# Conversational Text Chatbot with ChatGPT, Gemini and LangChain\n",
        "\n",
        "In this notebook you will use ChatGPT or Gemini and LangChain to build a conversational text-based chatbot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI and LangChain dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9F6lOBgXMk0"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.11\n",
        "!pip install langchain-openai==0.2.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3XbTsMsuEn2"
      },
      "source": [
        "# Optional: Install LangChain Google Gemini Dependency\n",
        "\n",
        "Google Gemini API is free (till now). You can get a key [here](https://aistudio.google.com/app/apikey), just need to sign in with your google account. Gemini may not be available fully in EU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_qohWceXMk1"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-google-genai==2.0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwGjVWK4q6F"
      },
      "source": [
        "## Load OpenAI API Credentials\n",
        "\n",
        "Here we load it from a file so we don't explore the credentials on the internet by mistake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e1HqI56y7t3"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryheOZuXxa41"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "with open('chatgpt_api_credentials.yml', 'r') as file:\n",
        "    api_creds = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZs7ts6NzADJ",
        "outputId": "9ddec629-3579-48c2-bbf6-29b2a07a0e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['openai_key'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api_creds.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDe44J0N0NcC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = api_creds['openai_key']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS7koM2emZ_M"
      },
      "source": [
        "## Optional: Load Gemini API credentials\n",
        "\n",
        "Run this section only if you are using Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxJAcO1MmhRo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "with open('gemini_key.yml', 'r') as file:\n",
        "    api_creds = yaml.safe_load(file)\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_creds['gemini_key']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWhgxCy5bA6"
      },
      "source": [
        "## Load Necessary Dependencies and ChatGPT LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GYhyRFRuJXG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY2bapqfuWq1"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CHIZflB3X6q"
      },
      "source": [
        "## Optional: Load Google Gemini LLM\n",
        "\n",
        "Only run the below cell if you don't want to use ChatGPT and want to use Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGXBXnHd3g6F"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini_model = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEtKuq9KntCF"
      },
      "source": [
        "## Build a Conversational Text Chatbot App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzLp_Fqme2u9"
      },
      "outputs": [],
      "source": [
        "# Import necessary components from the LangChain library.\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "\n",
        "def run_chatgpt_chatbot(system_prompt='', history_window=30,\n",
        "                        temperature=0.3, llm=model):\n",
        "  # Modify the core behavior of the LLM\n",
        "  if system_prompt:\n",
        "    SYS_PROMPT = system_prompt\n",
        "  else:\n",
        "    SYS_PROMPT = \"\"\"\n",
        "                  Act as a helpful AI Assistant\n",
        "                 \"\"\"\n",
        "  # Create a prompt template to store conversation history and accept new user prompts\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\", SYS_PROMPT),\n",
        "      MessagesPlaceholder(variable_name=\"history\"),\n",
        "      (\"human\", \"{input}\"),\n",
        "    ]\n",
        "  )\n",
        "  # Create a memory object to store conversation history window\n",
        "  memory = ConversationBufferWindowMemory(k=history_window,\n",
        "                                          return_messages=True)\n",
        "  # Create a conversation chain\n",
        "  conversation_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "      history=RunnableLambda(memory.load_memory_variables)\n",
        "      |\n",
        "      itemgetter(\"history\")\n",
        "    )\n",
        "    |\n",
        "    prompt\n",
        "    |\n",
        "    llm\n",
        "  )\n",
        "\n",
        "  # Print a welcome message when the chatbot starts.\n",
        "  print(\"Hello! I am your friendly chatbot. Let's chat! (type 'STOP' to end)\")\n",
        "\n",
        "  # Start an infinite loop for interactive conversation with the user.\n",
        "  while True:\n",
        "    # Get input from the user.\n",
        "    prompt = input('User: >>> ')\n",
        "    # Check if the user wants to end the chat.\n",
        "    if prompt.strip().upper() == 'STOP':\n",
        "      print(\"ChatGPT: >>> Goodbye!\")\n",
        "      break\n",
        "\n",
        "    # Generate and print the chatbot's reply.\n",
        "    user_inp = {'input': prompt}\n",
        "    reply = conversation_chain.invoke(user_inp)\n",
        "    print(f\"ChatGPT: >>>\\n{reply.content}\")\n",
        "    # remember to store your conversation to the memory object\n",
        "    memory.save_context(user_inp, {\"output\": reply.content})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UdH6mtTio_-",
        "outputId": "8c6ec31c-8fa9-4f79-a373-61856c921b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am your friendly chatbot. Let's chat! (type 'STOP' to end)\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User: >>>  Explain AI in 2 bullets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT: >>>\n",
            "- **Definition**: Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn, enabling them to perform tasks that typically require human cognitive functions, such as problem-solving, understanding language, and recognizing patterns.\n",
            "\n",
            "- **Applications**: AI is utilized across various fields, including healthcare (diagnosing diseases), finance (fraud detection), transportation (autonomous vehicles), and customer service (chatbots), enhancing efficiency and decision-making processes.\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User: >>>  Now do the same for Generative AI\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT: >>>\n",
            "- **Definition**: Generative AI is a subset of artificial intelligence that focuses on creating new content, such as text, images, music, or videos, by learning patterns from existing data and generating outputs that mimic human creativity.\n",
            "\n",
            "- **Applications**: Generative AI is used in diverse areas, including content creation (writing articles or generating art), game design (creating virtual environments), and personalized marketing (tailoring advertisements), enabling innovative solutions and enhancing user experiences.\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User: >>>  STOP\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT: >>> Goodbye!\n"
          ]
        }
      ],
      "source": [
        "run_chatgpt_chatbot() # default arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5peyF0v8kBVG",
        "outputId": "2c8a6065-52e0-4a34-af09-f3fa79d79f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am your friendly chatbot. Let's chat! (type 'STOP' to end)\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User: >>>  hello how are you doing?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT: >>>\n",
            "Oh, I'm just fantastic! You know, living the dream of being a sarcastic child. How about you? Did you have a thrilling day of adulting?\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User: >>>  stop\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatGPT: >>> Goodbye!\n"
          ]
        }
      ],
      "source": [
        "run_chatgpt_chatbot(system_prompt='Act as a sarcastic child') # Change LLM behavior"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}